{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Deliverable 2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media Post Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Reading Dataset From CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       subreddit                                               body  \\\n",
      "0  gameofthrones  Your submission has been automatically removed...   \n",
      "1            aww  Dont squeeze her with you massive hand, you me...   \n",
      "2         gaming  It's pretty well known and it was a paid produ...   \n",
      "3           news  You know we have laws against that currently c...   \n",
      "4       politics  Yes, there is a difference between gentle supp...   \n",
      "\n",
      "   controversiality  score  \n",
      "0                 0      1  \n",
      "1                 0     19  \n",
      "2                 0      3  \n",
      "3                 0     10  \n",
      "4                 0      1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"G2FinalDatasetReddit.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Checking Null or Missing Values in Dataset** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingdf = df.isnull().sum()\n",
    "missingdf[missingdf >0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Cleaning body Column Which COntains Comments Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         your submission has been automatically removed...\n",
       "1         dont squeeze her with you massive hand you mea...\n",
       "2         its pretty well known and it was a paid produc...\n",
       "3         you know we have laws against that currently c...\n",
       "4         yes there is a difference between gentle suppr...\n",
       "                                ...                        \n",
       "160394    lol im a spanish teacher and a kid spoiled it ...\n",
       "160395                                    yup glad hes good\n",
       "160396    i can literally see your shit eating grin afte...\n",
       "160397    if this is a dank meme upvote this comment if ...\n",
       "160398    the persecution of italianamericans persists e...\n",
       "Name: clean_body, Length: 160399, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>+', '', text)  \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['clean_body'] = df['body'].apply(clean_text)\n",
    "df['clean_body'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>score</th>\n",
       "      <th>clean_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>Your submission has been automatically removed...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>your submission has been automatically removed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>aww</td>\n",
       "      <td>Dont squeeze her with you massive hand, you me...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>dont squeeze her with you massive hand you mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>gaming</td>\n",
       "      <td>It's pretty well known and it was a paid produ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>its pretty well known and it was a paid produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "      <td>You know we have laws against that currently c...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>you know we have laws against that currently c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>politics</td>\n",
       "      <td>Yes, there is a difference between gentle supp...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>yes there is a difference between gentle suppr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159650</td>\n",
       "      <td>memes</td>\n",
       "      <td>lol i’m a spanish teacher and a kid spoiled it...</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>lol im a spanish teacher and a kid spoiled it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159651</td>\n",
       "      <td>nba</td>\n",
       "      <td>Yup. Glad he's good.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>yup glad hes good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159652</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>I can literally see your shit eating grin afte...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>i can literally see your shit eating grin afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159653</td>\n",
       "      <td>dankmemes</td>\n",
       "      <td>If this is a dank meme, **Upvote** this commen...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>if this is a dank meme upvote this comment if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159654</td>\n",
       "      <td>funny</td>\n",
       "      <td>The persecution of Italian-Americans persists ...</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>the persecution of italianamericans persists e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159655 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit                                               body  \\\n",
       "0        gameofthrones  Your submission has been automatically removed...   \n",
       "1                  aww  Dont squeeze her with you massive hand, you me...   \n",
       "2               gaming  It's pretty well known and it was a paid produ...   \n",
       "3                 news  You know we have laws against that currently c...   \n",
       "4             politics  Yes, there is a difference between gentle supp...   \n",
       "...                ...                                                ...   \n",
       "159650           memes  lol i’m a spanish teacher and a kid spoiled it...   \n",
       "159651             nba                               Yup. Glad he's good.   \n",
       "159652  wallstreetbets  I can literally see your shit eating grin afte...   \n",
       "159653       dankmemes  If this is a dank meme, **Upvote** this commen...   \n",
       "159654           funny  The persecution of Italian-Americans persists ...   \n",
       "\n",
       "        controversiality  score  \\\n",
       "0                      0      1   \n",
       "1                      0     19   \n",
       "2                      0      3   \n",
       "3                      0     10   \n",
       "4                      0      1   \n",
       "...                  ...    ...   \n",
       "159650                 0     68   \n",
       "159651                 0      1   \n",
       "159652                 0      2   \n",
       "159653                 0      1   \n",
       "159654                 0    222   \n",
       "\n",
       "                                               clean_body  \n",
       "0       your submission has been automatically removed...  \n",
       "1       dont squeeze her with you massive hand you mea...  \n",
       "2       its pretty well known and it was a paid produc...  \n",
       "3       you know we have laws against that currently c...  \n",
       "4       yes there is a difference between gentle suppr...  \n",
       "...                                                   ...  \n",
       "159650  lol im a spanish teacher and a kid spoiled it ...  \n",
       "159651                                  yup glad hes good  \n",
       "159652  i can literally see your shit eating grin afte...  \n",
       "159653  if this is a dank meme upvote this comment if ...  \n",
       "159654  the persecution of italianamericans persists e...  \n",
       "\n",
       "[159655 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['clean_body'].str.len() >= 10].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4 Saving Cleaned Dataset into New CSV File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Cleaned_Reddit_Comments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5 Check for empty strings in 'body' and 'clean_body'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_strings = (df['body'].str.strip() == '').sum()\n",
    "empty_clean_strings = (df['clean_body'].str.strip() == '').sum()\n",
    "\n",
    "print(\"Empty 'body' entries:\", empty_strings)\n",
    "print(\"Empty 'clean_body' entries:\", empty_clean_strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6 Rows with special characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "special_char_rows = df[df['clean_body'].str.contains(r'[^a-z\\s]', regex=True)]\n",
    "print(\" TotalRows with special characters:\", len(special_char_rows))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.7 Look for 'http' or 'www' in clean_body**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_rows = df[df['clean_body'].str.contains(r'(http|www\\.)', regex=True)]\n",
    "print(\"Total Rows with URLs:\", len(url_rows))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Embedding Using LLm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Instaling transformers and torch framework library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Importing transformers library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "texts = df['clean_body'].astype(str).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Initiallizing tokenizer and choosing Model for Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Checking If the Cuda interface is Available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 Method For Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text_list):\n",
    "    embeddings = []\n",
    "    for text in text_list:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            last_hidden = outputs.last_hidden_state\n",
    "            mask = inputs['attention_mask'].unsqueeze(-1).expand(last_hidden.size()).float()\n",
    "            masked_hidden = last_hidden * mask\n",
    "            summed = torch.sum(masked_hidden, 1)\n",
    "            summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "            mean_pooled = summed / summed_mask\n",
    "            embeddings.append(mean_pooled.cpu().numpy())\n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6 Calling Embeddings Method and Storing Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddings(texts)\n",
    "\n",
    "import numpy as np\n",
    "embeddings = np.vstack(embeddings)\n",
    "\n",
    "np.save('reddit_embeddings.npy', embeddings)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
